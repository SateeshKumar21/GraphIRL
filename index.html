<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Inverse Reinforcement Learning from Diverse Third-Person Videos via Graph Abstraction.">
  <meta name="keywords" content="Inverse Reinforcement Learning, Third-Person Videos, Graph Network">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>GraphIRL</title>
  

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>
  <!-- <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div> -->

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">Inverse Reinforcement Learning from Diverse<br> Third-Person Videos via Graph Abstraction</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://sateeshkumar21.github.io">Sateesh Kumar</a>,</span>
            <span class="author-block">
              <a href="https://jonzamora.dev">Jonathan Zamora</a><sup>*</sup>,</span>
            <span class="author-block">
              <a href="https://nicklashansen.github.io">Nicklas Hansen</a><sup>*</sup>,
            </span>
            <span class="author-block">
              <a href="https://jangirrishabh.github.io">Rishabh Jangir</a>,
            </span>
            <span class="author-block">
              <a href="https://xiaolonw.github.io">Xiaolong Wang</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">UC San Diego</span><br>
            <span style="font-size: 0.7em;">*Equal Contribution</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2207.14299.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!--arXiv Link.-->
              <span class="link-block">
                <a
                  href="https://arxiv.org/abs/2207.14299"
                  class="external-link button is-normal is-rounded is-dark"
                >
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=ts0e2HHp3Lk"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://sateeshkumar21.github.io/GraphIRL"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (Coming Soon)</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://sateeshkumar21.github.io/GraphIRL"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Dataset (Coming Soon)</span>
                  </a>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <center>
        <video id="teaser" autoplay muted loop playsinline width="100%">
          <source src="videos/GraphIRL Summary.mp4"
                  type="video/mp4">
        </video>
      </center>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">GraphIRL</span> uses a <strong>graph abstraction</strong> to learn a reward function
        from diverse 3rd-person human videos.
      </h2>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Research on Inverse Reinforcement Learning (IRL) from third-person videos has shown encouraging results on removing the need for manual reward design for robotic tasks. However, most prior works are still limited by training from a relatively restricted domain of videos. In this paper, we argue that the true potential of third-person IRL lies in increasing the diversity of videos for better scaling. To learn a reward function from diverse videos, we propose to perform graph abstraction on the videos followed by temporal matching in the graph space to measure the task progress. Our insight is that a task can be described by entity interactions that form a graph, and this graph abstraction can help remove irrelevant information such as textures, resulting in more robust reward functions. We evaluate our approach, <em>GraphIRL</em>, by learning from human demonstrations for real-robot manipulation and via cross-embodiment learning in X-MAGICAL. We show significant improvements in robustness to diverse video demonstrations over previous approaches, and even <b>achieve better results than manual reward design on real robot tasks</b>.
          </p>
          <br>
        </div>
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe width="560" height="315" src="https://www.youtube.com/embed/ts0e2HHp3Lk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
        </div>
        <br>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Method. -->
    <!--/ Method. -->
  </div>
</section>

<!-- Method-->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Method</h2>
        <div class="content has-text-justified">
          <p>
            <em>GraphIRL</em> is a self-supervised method for learning a visually invariant reward function directly from a set of diverse third-person video demonstrations via a graph abstraction. Our framework builds an object-centric graph abstraction from video demonstrations and then learns an embedding space that captures task progression by exploiting the temporal cue in the videos. This embedding space is then used to construct a <em>domain invariant</em> and <em>embodiment invariant</em> reward function which can be used to train any standard reinforcement learning algorithm.
          </p>
        </div>
        <center>
          <video id="teaser" autoplay muted loop playsinline controls height="100%">
            <source src="videos/GraphIRL 3x6 Human Demos.mp4"
                    type="video/mp4">
          </video>
        </center>
        <div class="content has-text-justified">
          <p>
            We have have 3 robotic manipulation tasks for which we gathered human demonstrations. From left-to-right, we have <em>Task (a): Reach</em>, <em>Task (b): Push</em>, and <em>Task (c): Peg in Box</em>. The video demonstrations have human hands completing the tasks with visually diverse goal regions, objects, and start-end locations for the human demonstrator.
          </p>
        </div>
      </div>
    </div>
    <!--/ Method. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <!-- Policy Learning in Sim. -->
      <div class="column">
        <div class="content">
          <h2 class="title is-4">Policy Learning in Sim</h2>
          <p>
            Upon gathering the demonstrations, we learn a temporally-aligned and embodiment-agnostic + domain-agnostic 
            reward function which is used for downstream RL policy learning.
          </p>
          <video id="sim" autoplay controls muted loop playsinline height="100%">
            <source src="videos/GraphIRL 3x3 Sim Videos.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ Policy Learning in Sim. -->

      <!-- Sim2Real. -->
      <div class="column">
        <h2 class="title is-4">Sim2Real Transfer</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              We transfer the learned policies from simulation to a real robot
              and observe that our method achieves competitive success rates compared to other vision-based baselines.
            </p>
            <video id="real" autoplay controls muted loop playsinline height="100%">
              <source src="videos/GraphIRL 3x3 Real Videos.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
    </div>
    <!--/ Sim2Real. -->

  <!-- </div> -->
</section>

<!-- Qualitative Comparison-->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Real Robot Results</h2>
        <div class="content has-text-justified">
          <center>
            <video autoplay muted loop playsinline controls height="100%" style="border-radius: 10px">
              <source src="videos/Reach Comparison.mp4"
                      type="video/mp4">
            </video>
          </center>

          <center>
            <video autoplay muted loop playsinline controls height="100%" style="border-radius: 10px">
              <source src="videos/Push Comparison.mp4"
                      type="video/mp4">
            </video>
          </center>

          <center>
            <video autoplay muted loop playsinline controls height="100%" style="border-radius: 10px">
              <source src="videos/Peg in Box Comparison.mp4"
                      type="video/mp4">
            </video>
          </center>
        </div>
      </div>
    </div>
    <!--/ Qualitative Comparison. -->
  </div>
</section>

<!-- Qualitative Comparison-->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Qualitative Analysis of Learned Reward</h2>
        <div class="content has-text-justified">
          <center>
            <video id="teaser" autoplay muted loop playsinline controls height="100%">
              <source src="videos/GraphIRL Task Success.mp4"
                      type="video/mp4">
            </video>
          </center>

          <center>
            <video id="teaser" autoplay muted loop playsinline controls height="100%">
              <source src="videos/GraphIRL Task Failure.mp4"
                      type="video/mp4">
            </video>
          </center>
        </div>
      </div>
    </div>
    <!--/ Qualitative Comparison. -->
  </div>
</section>

<!-- X-MAGICAL-->
<section class="section">
  <div class="container is-max-desktop">
    <!-- X-MAGICAL. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">X-MAGICAL Benchmark</h2>
        <div class="content has-text-justified">
          <p>
            In addition to evaluating <em>GraphIRL</em> on a range of robotic manipulation tasks, we also apply our method to the <em>X-MAGICAL</em> benchmark.
            With X-MAGICAL, we measure the performance of vision-based IRL baselines in the <strong>cross-embodiment cross-environment</strong> setting. For the purposes of
            our experiments, we leverage 2 variants of the X-MAGICAL environment: <em>standard</em> and <em>diverse</em>.
          </p>
          <center>
            <video id="teaser" autoplay muted loop playsinline controls height="100%">
              <source src="videos/GraphIRL X-MAGICAL.mp4"
                      type="video/mp4">
            </video>
          </center>
          <p>
            The goal for the agents in X-MAGICAL is to push three objects towards a static goal region. In the <strong>cross-embodiment cross-environment</strong> setting, we learn a reward function with <em>GraphIRL</em> on three of the four embodiments in one variant of the X-MAGICAL environment, and during RL, we use the learned reward function on an unseen embodiment in a visually different version of the environment.
          </p>
        </div>
      </div>
    </div>
    <!--/ X-MAGICAL. -->
  </div>
</section>

<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">Citation</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section> -->


<footer class="footer">
  <div class="container">
    <!-- <div class="content has-text-centered">
      <a class="icon-link"
         href="https://homes.cs.washington.edu/~kpar/nerfies/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div> -->
  </div>
</footer>

</body>
</html>
