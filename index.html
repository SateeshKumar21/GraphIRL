<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Graph Inverse Reinforcement Learning from Diverse Videos">
  <meta name="keywords" content="Inverse Reinforcement Learning, Third-Person Videos, Graph Network">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>GraphIRL</title>
  

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>
  <!-- <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div> -->

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">Graph Inverse Reinforcement Learning<br>from Diverse Videos</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://sateeshkumar21.github.io">Sateesh Kumar</a>,</span>
            <span class="author-block">
              <a href="https://jonzamora.dev">Jonathan Zamora</a><sup>*</sup>,</span>
            <span class="author-block">
              <a href="https://nicklashansen.github.io">Nicklas Hansen</a><sup>*</sup>,
            </span>
            <span class="author-block">
              <a href="https://jangirrishabh.github.io">Rishabh Jangir</a>,
            </span>
            <span class="author-block">
              <a href="https://xiaolonw.github.io">Xiaolong Wang</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">UC San Diego</span><br>
            <span style="font-size: 0.7em;">*Equal Contribution</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2207.14299.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!--arXiv Link.-->
              <span class="link-block">
                <a
                  href="https://arxiv.org/abs/2207.14299"
                  class="external-link button is-normal is-rounded is-dark"
                >
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=ts0e2HHp3Lk"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://sateeshkumar21.github.io/GraphIRL"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (Coming Soon)</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://sateeshkumar21.github.io/GraphIRL"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Dataset (Coming Soon)</span>
                  </a>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <center>
        <video id="teaser" autoplay muted loop playsinline width="100%">
          <source src="videos/GraphIRL Summary.mp4"
                  type="video/mp4">
        </video>
      </center>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Research on Inverse Reinforcement Learning (IRL) from third-person videos has shown encouraging results on removing the need for manual reward design for robotic tasks. However, most prior works are still limited by training from a relatively restricted domain of videos. In this paper, we argue that the true potential of third-person IRL lies in increasing the diversity of videos for better scaling. To learn a reward function from diverse videos, we propose to perform graph abstraction on the videos followed by temporal matching in the graph space to measure the task progress. Our insight is that a task can be described by entity interactions that form a graph, and this graph abstraction can help remove irrelevant information such as textures, resulting in more robust reward functions. We evaluate our approach, <em>GraphIRL</em>, by learning from human demonstrations for real-robot manipulation and via cross-embodiment learning in X-MAGICAL. We show significant improvements in robustness to diverse video demonstrations over previous approaches, and even <b>achieve better results than manual reward design on real robot tasks</b>.
          </p>
          <br>
        </div>
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe width="560" height="315" src="https://www.youtube.com/embed/hDxhmcwMFto" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
        </div>
        <br>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Method. -->
    <!--/ Method. -->
  </div>
</section>

<!-- Method-->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Graph Inverse Reinforcement Learning (GraphIRL)</h2>

        <div class="columns is-centered">
          <div class="column is-full-width">
            <tr>
              <td>
                <br>
                <div class="columns is-centered has-text-centered">
                  <img src="static/images/GraphIRL Method.png" style="width: 85%;"></img>
                </div>
              </td>
            </tr>
            <div class="is-vcentered interpolation-panel">
              <div class="content has-text-justified">
                <p style = "font-size: 18px">
                  <em>GraphIRL</em> is a self-supervised method for learning a visually invariant reward function directly from a set of diverse third-person video demonstrations via a graph abstraction. Our framework builds an object-centric graph abstraction from video demonstrations and then learns an embedding space that captures task progression by exploiting the temporal cue in the videos. This embedding space is then used to construct a <em>domain invariant</em> and <em>embodiment invariant</em> reward function which can be used to train any standard reinforcement learning algorithm.
                </p>
              </div>
            </div>
        </div>
        </div>

        <center>
          <video autoplay muted loop playsinline width="100%" style="border-radius: 10px">
            <source src="videos/GraphIRL 3x6 Human Demos.mp4"
                    type="video/mp4">
          </video>
        </center>

        <div class="content has-text-justified">
          <p>
            We have have 3 robotic manipulation tasks for which we gathered human demonstrations. From left-to-right, we have <em>Task (a): Reach</em>, <em>Task (b): Push</em>, and <em>Task (c): Peg in Box</em>. The video demonstrations have human hands completing the tasks with visually diverse goal regions, objects, and start-end locations for the human demonstrator.
          </p>
        </div>
      </div>
    </div>
    <!--/ Method. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <!-- Policy Learning in Sim. -->
      <div class="column">
        <div class="content">
          <h2 class="title is-4">Policy Learning in Sim</h2>
          <p>
            Upon gathering the demonstrations, we learn a temporally-aligned and embodiment-agnostic + domain-agnostic 
            reward function which is used for downstream RL policy learning.
          </p>
          <video autoplay muted loop playsinline width="100%" style="border-radius: 10px">
            <source src="videos/GraphIRL 3x3 Sim Videos.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ Policy Learning in Sim. -->

      <!-- Sim2Real. -->
      <div class="column">
        <h2 class="title is-4">Sim2Real Transfer</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              We transfer the learned policies from simulation to a real robot
              and observe that our method achieves competitive success rates compared to other vision-based baselines.
            </p>
            <video autoplay muted loop playsinline width="100%" style="border-radius: 10px">
              <source src="videos/GraphIRL 3x3 Real Videos.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
    </div>
    <!--/ Sim2Real. -->

  <!-- </div> -->
</section>

<!-- Qualitative Comparison-->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Real Robot Results</h2>
        <div class="content has-text-justified">
          <center>
            <video autoplay muted loop playsinline width="100%" style="border-radius: 10px">
              <source src="videos/Reach Comparison.mp4"
                      type="video/mp4">
            </video>
          </center>

          <center>
            <video autoplay muted loop playsinline width="100%" style="border-radius: 10px">
              <source src="videos/Push Comparison.mp4"
                      type="video/mp4">
            </video>
          </center>

          <center>
            <video autoplay muted loop playsinline width="100%" style="border-radius: 10px">
              <source src="videos/Peg in Box Comparison.mp4"
                      type="video/mp4">
            </video>
          </center>
        </div>
      </div>
    </div>
    <!--/ Qualitative Comparison. -->
  </div>
</section>

<!-- Qualitative Comparison-->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width has-text-justified">
        <h2 class="title is-3">Qualitative Analysis of Learned Reward</h2>
        <div class="content has-text-justified">
          <p>
            We visualize the learned reward for the <i>Peg in Box</i> task in 2 success videos and 1 failure video.
          </p>
          <br>
        </div>
        <div class="content has-text-justified">
          <center>
            <video autoplay muted loop playsinline width="100%" style="border-radius: 10px">
              <source src="videos/GraphIRL-Task-Success-1.mp4"
                      type="video/mp4">
            </video>
          </center>
          <center>
            <video autoplay muted loop playsinline width="100%" style="border-radius: 10px">
              <source src="videos/GraphIRL-Task-Success-2.mp4"
                      type="video/mp4">
            </video>
          </center>
          <center>
            <video autoplay muted loop playsinline width="100%" style="border-radius: 10px">
              <source src="videos/GraphIRL-Task-Failure.mp4"
                      type="video/mp4">
            </video>
          </center>
        </div>
      </div>
    </div>
    <!--/ Qualitative Comparison. -->
  </div>
</section>

<!-- X-MAGICAL-->
<section class="section">
  <div class="container is-max-desktop">
    <!-- X-MAGICAL. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">X-MAGICAL Benchmark</h2>
        <div class="content has-text-justified">
          <p>
            In addition to evaluating <em>GraphIRL</em> on a range of robotic manipulation tasks, we also apply our method to the <em>X-MAGICAL</em> benchmark.
            With X-MAGICAL, we measure the performance of vision-based IRL baselines in the <strong>cross-embodiment cross-environment</strong> setting. For the purposes of
            our experiments, we leverage 2 variants of the X-MAGICAL environment: <em>standard</em> and <em>diverse</em>.
          </p>
          <center>
            <video autoplay muted loop playsinline width="100%" style="border-radius: 10px">
              <source src="videos/GraphIRL X-MAGICAL.mp4"
                      type="video/mp4">
            </video>
          </center>
          <p>
            The goal for the agents in X-MAGICAL is to push three objects towards a static goal region. In the <strong>cross-embodiment cross-environment</strong> setting, we learn a reward function with <em>GraphIRL</em> on three of the four embodiments in one variant of the X-MAGICAL environment, and during RL, we use the learned reward function on an unseen embodiment in a visually different version of the environment.
          </p>
        </div>
      </div>
    </div>
    <!--/ X-MAGICAL. -->
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">

    <div style="margin: auto; margin-bottom: 64px; text-align: center;">
      <h2>Paper</h2>
      S. Kumar, J. Zamora*, N. Hansen*, R. Jangir, X. Wang<br/>
      <span class="bold">Graph Inverse Reinforcement Learning from Diverse Videos</span><br/><br/>
      arXiv, 2022<br/><br/>
      <div class="page" style="background-image: url(static/thumbnails/0.png);"></div>
      <div class="page" style="background-image: url(static/thumbnails/1.png);"></div>
      <div class="page" style="background-image: url(static/thumbnails/2.png);"></div>
      <div class="page" style="background-image: url(static/thumbnails/3.png);"></div>
      <div class="page" style="background-image: url(static/thumbnails/4.png);"></div>
      <div class="page" style="background-image: url(static/thumbnails/5.png);"></div>
      <div class="page" style="background-image: url(static/thumbnails/6.png);"></div>
      <div class="page" style="background-image: url(static/thumbnails/7.png);"></div>
      <div style="margin: auto; margin-top: 32px;">
        <a href="https://arxiv.org/abs/2207.14299">View on arXiv</a>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <h2>Citation</h2>
    </div>
    <p>If you use our method or code in your research, please consider citing the paper as follows:</p>
    <pre><code>@article{kumar2022inverse,
      title={Graph Inverse Reinforcement Learning from Diverse Videos},
      author={Kumar, Sateesh and Zamora, Jonathan and Hansen, Nicklas and Jangir, Rishabh and Wang, Xiaolong},
      journal={arXiv preprint arXiv:2207.14299},
      year={2022}
    }</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://arxiv.org/pdf/2207.14299.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://sateeshkumar21.github.io/GraphIRL/" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>This website template is borrowed from <a href="https://nerfies.github.io"><span class="dnerf">Nerfies</span></a>.</p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
